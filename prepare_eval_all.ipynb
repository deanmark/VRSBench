{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, json5\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import cprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = ['dam', 'storage-tank', 'ground-track-field', 'overpass', 'baseball-diamond', 'tennis-court', 'vehicle', 'basketball-court', 'golffield', 'harbor', 'expressway-service-area', 'chimney', 'trainstation', 'windmill', 'expressway-toll-station', 'ship', 'airport', 'bridge', 'airplane', 'stadium', 'soccer-ball-field', 'roundabout', 'swimming-pool', 'helicopter', 'container-crane', 'helipad']\n",
    "\n",
    "exclude_phrases = ['flag', 'not provide', 'not specified', 'unknown', 'referred', 'referring',\\\n",
    "    'nose', 'vertical stabilizer', ' tail', 'tail ', 'facing', 'pointing',\\\n",
    "    'first-mentioned', 'aforementioned', 'previously mentioned', 'motion', 'day', 'night', \n",
    "]\n",
    "\n",
    "correct_qa_types = ['object existence', 'object position', 'object quantity', 'object category', 'object color', 'object shape', 'object size', 'object direction', 'scene type', 'image', 'reasoning', 'rural or urban']\n",
    "\n",
    "all_files = glob.glob('./Human_Check/Label_Your_Data_Kaust_DOTA_VAL_cleaned/*.json') + glob.glob('Human_Check/Label_Your_Data_Kaust_DIOR_VAL_cleaned/*.json')\n",
    "\n",
    "all_files = [f for f in all_files if not f.endswith('input.json')]\n",
    "\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Referring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9350/9350 [04:05<00:00, 38.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_count 16159 9350 0\n"
     ]
    }
   ],
   "source": [
    "all_items = []\n",
    "valid_count = 0\n",
    "non_valid = []\n",
    "\n",
    "use_obb = False\n",
    "\n",
    "for json_path in tqdm(sorted(all_files)):\n",
    "    if json_path.endswith('input.json'):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json5.load(f)\n",
    "\n",
    "        if 'objects' in data:\n",
    "            all_refs = data['objects']\n",
    "\n",
    "        # item = {'id': json_path.split('.')[0], 'image': }\n",
    "        conversations = []\n",
    "        for ii, ref in enumerate(all_refs):\n",
    "            if 'referring_sentence' not in ref or 'obj_corner' not in ref or 'obj_cls' not in ref:\n",
    "                print('missing ref info', data['image'])\n",
    "            \n",
    "            x1,y1,x2,y2,x3,y3,x4,y4 = ref['obj_corner']\n",
    "            # convert coordinates to float\n",
    "            x1,y1,x2,y2,x3,y3,x4,y4 = map(float, [x1,y1,x2,y2,x3,y3,x4,y4])\n",
    "            # horizontal bounding box\n",
    "            xmin = max(min(x1,x2,x3,x4), 0)\n",
    "            xmax = min(max(x1,x2,x3,x4), 1)\n",
    "            ymin = max(min(y1,y2,y3,y4), 0)\n",
    "            ymax = min(max(y1,y2,y3,y4), 1)\n",
    "            # multiply by 100 to get integer\n",
    "            xmin = int(xmin * 100)\n",
    "            xmax = int(xmax * 100)\n",
    "            ymin = int(ymin * 100)\n",
    "            ymax = int(ymax * 100)\n",
    "\n",
    "            obj_cls = ref['obj_cls'].lower()\n",
    "            assert obj_cls in all_classes, obj_cls\n",
    "            \n",
    "            if use_obb:\n",
    "                # calculate angble beased on the above four cornet points\n",
    "                angle = np.arctan2(y2-y1, x2-x1) * 180 / np.pi\n",
    "                bbox_str = \"{\" + f\"<{x1}><{y1}><{x3}><{y3}>|<{angle}>\" + \"}\"\n",
    "            else:\n",
    "                bbox_str = \"{\" + f\"<{xmin}><{ymin}><{xmax}><{ymax}>\" + \"}\"\n",
    "            \n",
    "            obj_size = ref['obj_size']\n",
    "            \n",
    "            item_dict = {\n",
    "                \"image_id\": data['image'], \n",
    "                \"question\": ref['referring_sentence'], \n",
    "                \"ground_truth\": bbox_str, \n",
    "                \"dataset\": \"RSBench\", \n",
    "                \"question_id\": valid_count, \n",
    "                \"type\": \"ref\", \n",
    "                \"unique\": ref['is_unique'],\n",
    "                \"obj_corner\": ref['obj_corner'],\n",
    "                \"obj_cls\": obj_cls,\n",
    "                \"obj_ids\": [0, ], \n",
    "                \"size_group\": obj_size,\n",
    "            }\n",
    "            all_items.append(item_dict)\n",
    "        \n",
    "            valid_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print('skipping', json_path, 'error', e)\n",
    "        non_valid.append(json_path)\n",
    "        continue\n",
    "\n",
    "with open('RSBench_EVAL_referring_v2.json', 'w') as f:\n",
    "    json.dump(all_items, f, indent=4)\n",
    "\n",
    "print('valid_count', valid_count, len(all_files), len(non_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "convert = inflect.engine()\n",
    "all_numbers = [convert.number_to_words(x) for x in range(100)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9350/9350 [04:01<00:00, 38.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_count 37409 9350 0 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_items = []\n",
    "valid_count = 0\n",
    "non_valid = []\n",
    "\n",
    "use_obb = False\n",
    "skip_qas = 0\n",
    "for json_path in tqdm(sorted(all_files)):\n",
    "    if json_path.endswith('input.json'):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json5.load(f)\n",
    "\n",
    "        if 'qa_pairs' in data:\n",
    "            all_qas = data['qa_pairs']\n",
    "\n",
    "        for jj, qa in enumerate(all_qas):\n",
    "            if 'question' not in qa or 'answer' not in qa or 'type' not in qa:\n",
    "                print('missing qa info', data['image'])\n",
    "                continue\n",
    "            \n",
    "            skip = False\n",
    "            for phr in exclude_phrases + ['source', 'resolution']:\n",
    "                if phr in qa['answer'] or phr in qa['question']:\n",
    "                    print('skipping qa', json_path, 'due to', phr)\n",
    "                    skip = True\n",
    "                    skip_qas += 1\n",
    "                    break\n",
    "            if skip: continue\n",
    "            \n",
    "            skip = False\n",
    "            if 'which' in qa['question'].lower():\n",
    "                for num in range(100):\n",
    "                    if str(num) in qa['answer'] or all_numbers[num] in qa['answer']:\n",
    "                        skip = True\n",
    "                        skip_qas += 1\n",
    "                        print('question by object order, '+ qa['answer'])\n",
    "                        break\n",
    "            if skip: continue\n",
    "\n",
    "            qa['type'] = qa['type'].strip().lower()\n",
    "            assert qa['type'] in correct_qa_types, qa['type']\n",
    "\n",
    "            item_dict = {\n",
    "                \"image_id\": data['image'], \n",
    "                \"question\": qa['question'], \n",
    "                \"ground_truth\": qa['answer'], \n",
    "                \"dataset\": \"RSBench\", \n",
    "                \"question_id\": valid_count, \n",
    "                \"type\": qa['type'], \n",
    "            }\n",
    "            all_items.append(item_dict)\n",
    "        \n",
    "            valid_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print('skipping', json_path, 'error', e)\n",
    "        non_valid.append(json_path)\n",
    "        continue\n",
    "\n",
    "with open('RSBench_EVAL_vqa_v2.json', 'w') as f:\n",
    "    json.dump(all_items, f, indent=4)\n",
    "\n",
    "print('valid_count', valid_count, len(all_files), len(non_valid), skip_qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37409, 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_count, skip_qas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9350/9350 [04:02<00:00, 38.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_count 9350 9350 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_items = []\n",
    "valid_count = 0\n",
    "non_valid = []\n",
    "\n",
    "use_obb = False\n",
    "\n",
    "for json_path in tqdm(sorted(all_files)):\n",
    "    if json_path.endswith('input.json'):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json5.load(f)\n",
    "\n",
    "        if 'caption' in data:\n",
    "            caption = data['caption']\n",
    "            item_dict = {\n",
    "                \"image_id\": data['image'], \n",
    "                \"ground_truth\": caption, \n",
    "                \"question\": \"Describe the image in detail\",\n",
    "                \"dataset\": \"RSBench\", \n",
    "                \"question_id\": valid_count, \n",
    "                \"type\": \"caption\", \n",
    "            }\n",
    "            all_items.append(item_dict)\n",
    "        \n",
    "            valid_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print('skipping', json_path, 'error', e)\n",
    "        non_valid.append(json_path)\n",
    "        continue\n",
    "\n",
    "with open('RSBench_EVAL_Cap_v2.json', 'w') as f:\n",
    "    json.dump(all_items, f, indent=4)\n",
    "\n",
    "print('valid_count', valid_count, len(all_files), len(non_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
